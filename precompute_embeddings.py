#!/usr/bin/env python3
"""
Pre-compute embeddings for Streamlit Cloud deployment
Run this once locally, then commit the cache files to GitHub
"""

import sys
import os
sys.path.append('src')

from src.embedding_cache import EmbeddingCache

def main():
    print("ğŸš€ Pre-computing embeddings for Streamlit Cloud...")
    print("This will create cache files that can be deployed to Streamlit Cloud")
    print("=" * 60)
    
    # Initialize cache
    cache = EmbeddingCache()
    
    # JSON files to process
    json_files = [
        "data/matura_21_05_2025.json",
        "data/matura_2025_avgust.json"
    ]
    
    # Check if files exist
    missing_files = [f for f in json_files if not os.path.exists(f)]
    if missing_files:
        print(f"âŒ Missing files: {missing_files}")
        return
    
    # Compute and cache embeddings
    print("ğŸ”„ Computing embeddings...")
    cache_data = cache.compute_and_cache_embeddings(json_files)
    
    print(f"\nâœ… Pre-computation complete!")
    print(f"ğŸ“Š Cached {cache_data['total_questions']} questions")
    print(f"ğŸ“ Cache file: cache/embeddings_cache.pkl")
    print(f"ğŸ“ Embedding dimension: {cache_data['model_name']}")
    
    # Test similarity search
    print("\nğŸ” Testing similarity search...")
    test_query = "ĞšĞ¾Ğ¹ ĞºĞ¾Ğ½Ñ„Ğ»Ğ¸ĞºÑ‚ Ğµ Ğ·Ğ°Ğ»Ğ¾Ğ¶ĞµĞ½ Ğ² Ğ¸Ğ½Ñ‚ĞµÑ€Ğ¿Ñ€ĞµÑ‚Ğ°Ñ†Ğ¸ÑÑ‚Ğ° Ğ½Ğ° Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ° Ğ·Ğ° Ñ‡Ğ¾Ğ²ĞµĞºĞ° Ğ¸ Ğ²Ğ»Ğ°ÑÑ‚Ñ‚Ğ°"
    similar = cache.get_similar_questions(test_query, top_k=3)
    
    print(f"Query: {test_query}")
    for idx, similarity in similar:
        question = cache_data['questions'][idx]
        print(f"Similarity: {similarity:.3f} - {question.get('question', '')[:100]}...")
    
    print("\nğŸ“‹ Next steps:")
    print("1. Commit the cache/ directory to GitHub")
    print("2. Deploy to Streamlit Cloud")
    print("3. The app will use cached embeddings (fast startup)")

if __name__ == "__main__":
    main()
