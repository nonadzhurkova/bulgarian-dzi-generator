"""
Simple RAG Question Generator - Phase 2
Uses only OpenAI API without heavy models
"""

import os
import json
import random
import logging
from typing import List, Dict, Any
from enum import Enum

# Load environment variables from .env file
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

# Setup logging to file
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('rag_generator.log', encoding='utf-8', mode='w'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class SubjectArea(Enum):
    LANGUAGE = "language"
    LITERATURE = "literature"

class SimpleRAGGenerator:
    """Simple RAG generator using only OpenAI API"""
    
    def __init__(self):
        self.api_key = os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            raise ValueError("OPENAI_API_KEY not found in environment variables")
        
        # Load real questions for context
        self.real_questions = self._load_real_questions()
        
    def _load_real_questions(self) -> List[Dict]:
        """Load real questions from JSON files"""
        questions = []
        
        # Load from matura files
        for file_path in ['data/matura_21_05_2025.json', 'data/matura_2025_avgust.json']:
            if os.path.exists(file_path):
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        if isinstance(data, list):
                            questions.extend(data)
                        elif isinstance(data, dict) and 'questions' in data:
                            questions.extend(data['questions'])
                except Exception as e:
                    print(f"Error loading {file_path}: {e}")
        
        return questions
    
    def _get_openai_client(self):
        """Get OpenAI client"""
        try:
            from openai import OpenAI
            return OpenAI(api_key=self.api_key)
        except ImportError:
            raise ImportError("OpenAI library not installed. Run: pip install openai")
    
    def _find_similar_questions(self, subject: SubjectArea, count: int = 3) -> List[Dict]:
        """Find similar questions from real data"""
        logger.info(f"üîç [RAG] Searching for similar questions in {len(self.real_questions)} real questions")
        
        # Since the data doesn't have subject field, we'll use content-based filtering
        similar = []
        
        if subject == SubjectArea.LANGUAGE:
            # Look for language-related keywords in questions
            language_keywords = [
                '–ø—Ä–∞–≤–æ–ø–∏—Å', '–≥—Ä–∞–º–∞—Ç–∏–∫–∞', '—Å–∏–Ω—Ç–∞–∫—Å–∏—Å', '–º–æ—Ä—Ñ–æ–ª–æ–≥–∏—è', '—Ñ–æ–Ω–µ—Ç–∏–∫–∞',
                '–¥—É–º–∞', '–∏–∑—Ä–µ—á–µ–Ω–∏–µ', '–∑–≤—É–∫', '–±—É–∫–≤–∞', '—Å—Ä–∏—á–∫–∞', '—Å—ä–≥–ª–∞—Å–Ω–∞', '–≥–ª–∞—Å–Ω–∞',
                '–ø—Ä–∞–≤–æ–ø–∏—Å–Ω–∞', '–≥—Ä–∞–º–∞—Ç–∏—á–µ—Å–∫–∞', '—Å–∏–Ω—Ç–∞–∫—Ç–∏—á–Ω–∞', '–º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–Ω–∞',
                '–∏–∑–ø–∏—Å–∞–Ω–∞', '–ø—Ä–∞–≤–∏–ª–Ω–æ', '–≥—Ä–µ—à–∫–∞', '–ø—Ä–∞–≤–æ–ø–∏—Å–Ω–∞ –≥—Ä–µ—à–∫–∞'
            ]
            
            for q in self.real_questions:
                question_text = q.get('question', '').lower()
                if any(keyword in question_text for keyword in language_keywords):
                    similar.append(q)
                    
        else:  # LITERATURE
            # Look for literature-related keywords
            literature_keywords = [
                '–∞–≤—Ç–æ—Ä', '–ø–∏—Å–∞—Ç–µ–ª', '–ø–æ–µ—Ç', '—Ä–æ–º–∞–Ω', '–ø–æ–≤–µ—Å—Ç', '—Ä–∞–∑–∫–∞–∑', '—Å—Ç–∏—Ö–æ—Ç–≤–æ—Ä–µ–Ω–∏–µ',
                '–ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞', '—Ç–≤–æ—Ä–±–∞', '–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ', '–ø–µ—Ä—Å–æ–Ω–∞–∂', '–≥–µ—Ä–æ–π',
                '–ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–µ–Ω', '—Ö—É–¥–æ–∂–µ—Å—Ç–≤–µ–Ω', '–µ–ø–∏—á–µ—Å–∫–∏', '–ª–∏—Ä–∏—á–µ—Å–∫–∏', '–¥—Ä–∞–º–∞—Ç–∏—á–µ—Å–∫–∏'
            ]
            
            for q in self.real_questions:
                question_text = q.get('question', '').lower()
                if any(keyword in question_text for keyword in literature_keywords):
                    similar.append(q)
        
        logger.info(f"üîç [RAG] Found {len(similar)} similar questions using keyword matching")
        
        # If no keyword matches, use random questions as fallback
        if not similar:
            logger.warning("‚ö†Ô∏è [RAG] No keyword matches found, using random questions as fallback")
            similar = self.real_questions[:min(count, len(self.real_questions))]
        
        # Return random sample
        return random.sample(similar, min(count, len(similar)))
    
    def _generate_with_openai(self, subject: SubjectArea, count: int, similar_questions: List[Dict]) -> List[Dict]:
        """Generate questions using OpenAI API"""
        logger.info(f"üöÄ [RAG] Starting OpenAI generation for {subject.value} - {count} questions")
        logger.info(f"üîë [RAG] API Key configured: {bool(self.api_key)}")
        
        client = self._get_openai_client()
        logger.info(f"‚úÖ [RAG] OpenAI client initialized")
        
        # Prepare context from similar questions
        context = ""
        for i, q in enumerate(similar_questions[:3]):
            context += f"–ü—Ä–∏–º–µ—Ä {i+1}:\n"
            context += f"–í—ä–ø—Ä–æ—Å: {q.get('question', 'N/A')}\n"
            context += f"–û–ø—Ü–∏–∏: {', '.join(q.get('options', []))}\n"
            context += f"–ü—Ä–∞–≤–∏–ª–µ–Ω –æ—Ç–≥–æ–≤–æ—Ä: {q.get('correct_answer', 'N/A')}\n\n"
        
        logger.info(f"üìù [RAG] Context prepared with {len(similar_questions)} similar questions")
        
        # Create prompt
        subject_name = "–ë—ä–ª–≥–∞—Ä—Å–∫–∏ –µ–∑–∏–∫" if subject == SubjectArea.LANGUAGE else "–ë—ä–ª–≥–∞—Ä—Å–∫–∞ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞"
        
        prompt = f"""–ì–µ–Ω–µ—Ä–∏—Ä–∞–π {count} –Ω–æ–≤–∏ –≤—ä–ø—Ä–æ—Å–∞ –∑–∞ {subject_name} –≤ —Å—Ç–∏–ª–∞ –Ω–∞ –î–ó–ò –º–∞—Ç—É—Ä–∞.

–ö–æ–Ω—Ç–µ–∫—Å—Ç –æ—Ç —Ä–µ–∞–ª–Ω–∏ –≤—ä–ø—Ä–æ—Å–∏:
{context}

–ò–∑–∏—Å–∫–≤–∞–Ω–∏—è:
- –í—ä–ø—Ä–æ—Å–∏—Ç–µ —Ç—Ä—è–±–≤–∞ –¥–∞ —Å–∞ –Ω–∞ –±—ä–ª–≥–∞—Ä—Å–∫–∏ –µ–∑–∏–∫
- –í—Å–µ–∫–∏ –≤—ä–ø—Ä–æ—Å —Ç—Ä—è–±–≤–∞ –¥–∞ –∏–º–∞ 4 –æ–ø—Ü–∏–∏ (A, B, C, D)
- –¢—Ä—è–±–≤–∞ –¥–∞ –∏–º–∞ —Å–∞–º–æ –µ–¥–∏–Ω –ø—Ä–∞–≤–∏–ª–µ–Ω –æ—Ç–≥–æ–≤–æ—Ä
- –°—Ç–∏–ª—ä—Ç —Ç—Ä—è–±–≤–∞ –¥–∞ –µ –∫–∞—Ç–æ –Ω–∞ —Ä–µ–∞–ª–Ω–∏—Ç–µ –≤—ä–ø—Ä–æ—Å–∏
- –¢—Ä—É–¥–Ω–æ—Å—Ç—Ç–∞ —Ç—Ä—è–±–≤–∞ –¥–∞ –µ —Ä–∞–∑–ª–∏—á–Ω–∞ (easy, medium, hard)

–û—Ç–≥–æ–≤–æ—Ä–∏ –≤ JSON —Ñ–æ—Ä–º–∞—Ç:
{{
  "questions": [
    {{
      "question": "–¢–µ–∫—Å—Ç –Ω–∞ –≤—ä–ø—Ä–æ—Å–∞",
      "options": ["–û–ø—Ü–∏—è A", "–û–ø—Ü–∏—è B", "–û–ø—Ü–∏—è C", "–û–ø—Ü–∏—è D"],
      "correct_answer": "–ü—Ä–∞–≤–∏–ª–Ω–∞—Ç–∞ –æ–ø—Ü–∏—è",
      "subject": "{subject_name}",
      "difficulty": "easy/medium/hard",
      "points": 1
    }}
  ]
}}"""
        
        try:
            logger.info(f"üåê [RAG] Sending request to OpenAI API...")
            
            # Try gpt-5-nano first, fallback to gpt-3.5-turbo
            try:
                logger.info(f"üìä [RAG] Trying gpt-5-nano, Max completion tokens: 2000")
                response = client.chat.completions.create(
                    model="gpt-4.1-nano",
                    messages=[
                        {"role": "system", "content": "–¢–∏ —Å–∏ –µ–∫—Å–ø–µ—Ä—Ç –ø–æ –±—ä–ª–≥–∞—Ä—Å–∫–∏ –µ–∑–∏–∫ –∏ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–∞–Ω –≤ —Å—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ –≤—ä–ø—Ä–æ—Å–∏ –∑–∞ –î–ó–ò –º–∞—Ç—É—Ä–∞."},
                        {"role": "user", "content": prompt}
                    ],
                    max_completion_tokens=2000
                )
                logger.info(f"‚úÖ [RAG] Successfully used gpt-5-nano")
            except Exception as nano_error:
                logger.warning(f"‚ö†Ô∏è [RAG] gpt-5-nano failed: {nano_error}")
                logger.info(f"üìä [RAG] Falling back to gpt-4.1-nano-2025-04-14, Max completion tokens: 2000")
                response = client.chat.completions.create(
                    model="gpt-4.1-nano-2025-04-14",
                    messages=[
                        {"role": "system", "content": "–¢–∏ —Å–∏ –µ–∫—Å–ø–µ—Ä—Ç –ø–æ –±—ä–ª–≥–∞—Ä—Å–∫–∏ –µ–∑–∏–∫ –∏ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–∞–Ω –≤ —Å—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ –≤—ä–ø—Ä–æ—Å–∏ –∑–∞ –î–ó–ò –º–∞—Ç—É—Ä–∞."},
                        {"role": "user", "content": prompt}
                    ],
                    max_completion_tokens=2000
                )
                logger.info(f"‚úÖ [RAG] Successfully used gpt-4.1-nano-2025-04-14 fallback")
            
            logger.info(f"‚úÖ [RAG] OpenAI API response received!")
            logger.info(f"üìù [RAG] Response length: {len(response.choices[0].message.content)} characters")
            
            # Parse response
            content = response.choices[0].message.content.strip()
            logger.info(f"üìù [RAG] Raw response content: '{content}'")
            
            # Check if response is empty (gpt-5-nano issue)
            if not content:
                logger.warning(f"‚ö†Ô∏è [RAG] Empty response received, trying fallback to gpt-4.1-nano-2025-04-14")
                response = client.chat.completions.create(
                    model="gpt-4.1-nano-2025-04-14",
                    messages=[
                        {"role": "system", "content": "–¢–∏ —Å–∏ –µ–∫—Å–ø–µ—Ä—Ç –ø–æ –±—ä–ª–≥–∞—Ä—Å–∫–∏ –µ–∑–∏–∫ –∏ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–∞–Ω –≤ —Å—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ –≤—ä–ø—Ä–æ—Å–∏ –∑–∞ –î–ó–ò –º–∞—Ç—É—Ä–∞."},
                        {"role": "user", "content": prompt}
                    ],
                    max_completion_tokens=2000
                )
                content = response.choices[0].message.content.strip()
                logger.info(f"‚úÖ [RAG] Fallback response: '{content[:100]}...'")
            
            # Try to extract JSON
            if "```json" in content:
                json_start = content.find("```json") + 7
                json_end = content.find("```", json_start)
                json_content = content[json_start:json_end].strip()
            elif "{" in content and "}" in content:
                json_start = content.find("{")
                json_end = content.rfind("}") + 1
                json_content = content[json_start:json_end]
            else:
                logger.error(f"‚ùå [RAG] No JSON found in response. Content: '{content}'")
                raise ValueError("No JSON found in response")
            
            result = json.loads(json_content)
            questions = result.get("questions", [])
            logger.info(f"üéØ [RAG] Successfully parsed {len(questions)} questions from OpenAI response")
            return questions
            
        except Exception as e:
            logger.error(f"‚ùå [RAG] Error generating with OpenAI: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return []
    
    def generate_questions(self, count: int, subject: SubjectArea) -> List[Dict]:
        """Generate new questions using RAG approach"""
        logger.info(f"üéØ [RAG] Starting question generation: {count} questions for {subject.value}")
        
        if not self.api_key:
            logger.error("‚ùå [RAG] OpenAI API key not configured")
            raise ValueError("OpenAI API key not configured")
        
        logger.info(f"‚úÖ [RAG] API key found: {self.api_key[:10]}...")
        
        # Find similar questions for context
        similar_questions = self._find_similar_questions(subject, 3)
        logger.info(f"üîç [RAG] Found {len(similar_questions)} similar questions for context")
        
        if not similar_questions:
            logger.warning("‚ö†Ô∏è [RAG] No similar questions found, using basic generation")
            return self._generate_basic_questions(count, subject)
        
        # Generate with OpenAI
        logger.info(f"üöÄ [RAG] Proceeding with OpenAI generation...")
        generated = self._generate_with_openai(subject, count, similar_questions)
        
        if not generated:
            logger.warning("‚ö†Ô∏è [RAG] OpenAI generation failed, using basic generation")
            return self._generate_basic_questions(count, subject)
        
        logger.info(f"‚úÖ [RAG] Successfully generated {len(generated)} questions!")
        return generated
    
    def _generate_basic_questions(self, count: int, subject: SubjectArea) -> List[Dict]:
        """Fallback basic generation without API"""
        questions = []
        
        if subject == SubjectArea.LANGUAGE:
            templates = [
                {
                    "question": "–ö–æ–π –æ—Ç —Å–ª–µ–¥–Ω–∏—Ç–µ –¥—É–º–∏ –µ —Å–∏–Ω–æ–Ω–∏–º –Ω–∞ '–∏–∑–∫–ª—é—á–∏—Ç–µ–ª–µ–Ω'?",
                    "options": ["–æ–±–∏–∫–Ω–æ–≤–µ–Ω", "—Ä–µ–¥–æ–≤–µ–Ω", "–∏–∑–≤—ä–Ω—Ä–µ–¥–µ–Ω", "—Å—Ç–∞–Ω–¥–∞—Ä—Ç–µ–Ω"],
                    "correct_answer": "–∏–∑–≤—ä–Ω—Ä–µ–¥–µ–Ω"
                },
                {
                    "question": "–ö–æ–π –æ—Ç —Å–ª–µ–¥–Ω–∏—Ç–µ –¥—É–º–∏ –µ –∞–Ω—Ç–æ–Ω–∏–º –Ω–∞ '–¥–æ–±—ä—Ä'?",
                    "options": ["—Ö—É–±–∞–≤", "–ª–æ—à", "–¥–æ–±—ä—Ä", "–æ—Ç–ª–∏—á–µ–Ω"],
                    "correct_answer": "–ª–æ—à"
                }
            ]
        else:
            templates = [
                {
                    "question": "–ö–æ–π –µ –∞–≤—Ç–æ—Ä—ä—Ç –Ω–∞ —Ä–æ–º–∞–Ω–∞ '–ü–æ–¥ –∏–≥–æ—Ç–æ'?",
                    "options": ["–ò–≤–∞–Ω –í–∞–∑–æ–≤", "–•—Ä–∏—Å—Ç–æ –ë–æ—Ç–µ–≤", "–ü–µ–π–æ –Ø–≤–æ—Ä–æ–≤", "–î–∏–º—á–æ –î–µ–±–µ–ª—è–Ω–æ–≤"],
                    "correct_answer": "–ò–≤–∞–Ω –í–∞–∑–æ–≤"
                },
                {
                    "question": "–í –∫–æ–π –ø–µ—Ä–∏–æ–¥ –µ —Å—ä–∑–¥–∞–¥–µ–Ω–∞ –ø–æ–µ–º–∞—Ç–∞ '–•–∞–π–¥—É—à–∫–∏'?",
                    "options": ["–í—ä–∑—Ä–∞–∂–¥–∞–Ω–µ—Ç–æ", "–°—Ä–µ–¥–Ω–æ–≤–µ–∫–æ–≤–∏–µ—Ç–æ", "–ê–Ω—Ç–∏—á–Ω–æ—Å—Ç—Ç–∞", "–ú–æ–¥–µ—Ä–Ω–∏–∑–º–∞"],
                    "correct_answer": "–í—ä–∑—Ä–∞–∂–¥–∞–Ω–µ—Ç–æ"
                }
            ]
        
        # Generate requested number of questions
        for i in range(count):
            template = random.choice(templates)
            question = template.copy()
            question["subject"] = "–ë—ä–ª–≥–∞—Ä—Å–∫–∏ –µ–∑–∏–∫" if subject == SubjectArea.LANGUAGE else "–ë—ä–ª–≥–∞—Ä—Å–∫–∞ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞"
            question["difficulty"] = random.choice(["easy", "medium", "hard"])
            question["points"] = 1
            questions.append(question)
        
        return questions
    
    def add_question_to_database(self, question: Dict):
        """Add a new question to the real questions database"""
        logger.info(f"üìù [RAG] Adding new question to database: {question.get('question', 'N/A')[:50]}...")
        self.real_questions.append(question)
        logger.info(f"‚úÖ [RAG] Question added. Total questions: {len(self.real_questions)}")
    
    def add_questions_to_database(self, questions: List[Dict]):
        """Add multiple questions to the real questions database"""
        logger.info(f"üìù [RAG] Adding {len(questions)} new questions to database")
        for question in questions:
            self.real_questions.append(question)
        logger.info(f"‚úÖ [RAG] All questions added. Total questions: {len(self.real_questions)}")
